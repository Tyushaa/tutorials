{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b412cd",
   "metadata": {},
   "source": [
    "# Building a Documentation Chatbot with LangChain\n",
    "\n",
    "This script demonstrates how to build an intelligent chatbot that queries documentation using LangChain.\n",
    "The chatbot can:\n",
    "- Parse and preprocess Markdown files.\n",
    "- Embed document content for efficient similarity-based retrieval.\n",
    "- Answer detailed, context-aware queries from users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "532dfea4-93b4-41e2-b6c1-5d7f57a4140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo /venv/bin/pip install langchain --quiet\n",
    "#!sudo /venv/bin/pip install -U langchain-community --quiet\n",
    "#!sudo /venv/bin/pip install -U langchain-openai --quiet\n",
    "#!sudo /venv/bin/pip install -U langchain-core --quiet\n",
    "#!sudo /venv/bin/pip install -U langchainhub --quiet\n",
    "#!sudo /venv/bin/pip install -U unstructured python-magic pandoc markdown faiss-cpu --quiet\n",
    "#!sudo /venv/bin/pip install --quiet chromadb\n",
    "\n",
    "!sudo /venv/bin/pip install -U --quiet unstructured markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f52147f7-f5c1-460f-a110-5c708e569070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cafda052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import helpers.hdbg as hdbg\n",
    "import langchain\n",
    "import langchain.chains\n",
    "import langchain.docstore.document as lngchdocstordoc\n",
    "import langchain.embeddings\n",
    "import langchain.hub\n",
    "import langchain.text_splitter\n",
    "import langchain_openai\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d76dc826-908c-4ecf-a5b9-c80b30f46256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "014b1dd4-f9ec-4263-8f53-657e4a7f64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING\u001b[0m: Logger already initialized: skipping\n"
     ]
    }
   ],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a42c7e-203e-406d-a315-e5853fd2f000",
   "metadata": {},
   "source": [
    "## Define Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38a40064-5415-49c9-b2d5-354a839b9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Define language model arguments.\n",
    "    \"language_model\": {\n",
    "        # Define your model here.\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    # Define input directory path containing documents.\n",
    "    \"source_directory\": \"docs\",\n",
    "    \"parse_data_into_chunks\": {\n",
    "        \"chunk_size\": 500,\n",
    "        \"chunk_overlap\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "hdbg.dassert_dir_exists(config[\"source_directory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208ea51-4419-4137-89a2-5f2756c14f1d",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "We'll begin by importing the required libraries and configuring the environment. The chatbot will use:\n",
    "- OpenAI's GPT-4o-mini as the core language model.\n",
    "- FAISS for fast document retrieval.\n",
    "- LangChain utilities for document parsing, text splitting, and chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac548ed5-8093-43b0-a498-e17ebb61b0e0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4o-mini', 'temperature': 0}\n"
     ]
    }
   ],
   "source": [
    "# Set the OpenAI API key.\n",
    "#os.environ[\"OPENAI_API_KEY\"] = config[\"open_ai_api_key\"]\n",
    "# Initialize the chat model.\n",
    "print(config[\"language_model\"])\n",
    "chat_model = langchain_openai.ChatOpenAI(**config[\"language_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c3a1e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542cfc8",
   "metadata": {},
   "source": [
    "## Parse and Preprocess Documentation\n",
    "\n",
    "Markdown files serve as the primary data source for this chatbot.\n",
    "We'll parse the files into LangChain `Document` objects and split them into manageable chunks to ensure efficient retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5f91f41-afe7-49fa-9859-397009613558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  Found 16 markdown files in docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  Successfully parsed 16/16 files\n",
      "INFO  Split 16 documents into 184 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize with documents\n",
    "md_files = ut.list_markdown_files(config[\"source_directory\"])\n",
    "raw_documents = ut.parse_markdown_files(md_files)\n",
    "chunked_documents = ut.split_documents(\n",
    "    raw_documents,\n",
    "    chunk_size=config[\"parse_data_into_chunks\"][\"chunk_size\"],\n",
    "    chunk_overlap=config[\"parse_data_into_chunks\"][\"chunk_overlap\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31074294",
   "metadata": {},
   "source": [
    "## Create a FAISS Vector Store\n",
    "\n",
    "To enable fast document retrieval, we'll embed the document chunks using OpenAI's embeddings and store them in a FAISS vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63a3a326-140a-4543-8f01-155e0fa36192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO  Created vector store with 184 entries\n",
      "INFO  FAISS vector store created with 184 documents.\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI embeddings.\n",
    "embeddings = langchain.embeddings.OpenAIEmbeddings()\n",
    "# Create a FAISS vector store.\n",
    "vector_store = ut.create_vector_store(chunked_documents, embeddings)\n",
    "_LOG.info(\"FAISS vector store created with %d documents.\", len(chunked_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23fd80",
   "metadata": {},
   "source": [
    "## Build a QA Chain\n",
    "\n",
    "The `RetrievalQA` chain combines document retrieval with OpenAI's GPT-3.5 for question answering.\n",
    "It retrieves the most relevant document chunks and uses them as context to generate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bab54142-1414-4d82-a6e1-1a51db624dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  Built retriever with config: {'k': 4}\n",
      "INFO  RetrievalQA chain initialized.\n"
     ]
    }
   ],
   "source": [
    "# Build the retriever from the vector store\n",
    "retriever = ut.build_retriever(vector_store)\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = langchain.chains.RetrievalQA.from_chain_type(\n",
    "    llm=chat_model, retriever=retriever, return_source_documents=True\n",
    ")\n",
    "\n",
    "_LOG.info(\"RetrievalQA chain initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e262aba",
   "metadata": {},
   "source": [
    "## Step 5: Query the Chatbot\n",
    "\n",
    "Let's interact with the chatbot! We'll ask it questions based on the documentation.\n",
    "The chatbot will retrieve relevant chunks and generate context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427c7461-6d5c-4125-a2f4-2a57e5b62b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answer:\n",
      "I don't know.\n",
      "\n",
      "Source Documents:\n",
      "- Source: docs/onboarding/intern.onboarding_checklist.reference.md\n",
      "  Excerpt: IT setup\n",
      "\n",
      "[ ] Intern: Set up the development environment following instructions in intern.set_up_development_on_laptop.how_to_guide.md\n",
      "\n",
      "Must-read\n",
      "\n",
      "[ ] Intern: Carefully study all the documents in the \n",
      "- Source: docs/onboarding/all.dev_must_read_checklist.reference.md\n",
      "  Excerpt: Must-read documents for a new team member\n",
      "\n",
      "Org\n",
      "\n",
      "Coding\n",
      "\n",
      "Submitting your code for review\n",
      "\n",
      "Git(Hub)\n",
      "\n",
      "Writing docs\n",
      "\n",
      "Beyond the must-read\n",
      "\n",
      "Must-read documents for a new team member\n",
      "\n",
      "Org\n",
      "\n",
      "[ ] General rules\n",
      "- Source: docs/onboarding/all.development_documents.reference.md\n",
      "  Excerpt: Development Documents\n",
      "\n",
      "On-boarding\n",
      "\n",
      "How to start developing\n",
      "\n",
      "Project management\n",
      "\n",
      "Learn how to become efficient at developing\n",
      "\n",
      "In-depth docs\n",
      "\n",
      "DeFi\n",
      "\n",
      "image\n",
      "\n",
      "On-boarding\n",
      "\n",
      "Signing up for KaizenFlow\n",
      "\n",
      "How to\n",
      "- Source: docs/onboarding/ck.development_setup.how_to_guide.md\n",
      "  Excerpt: Development Setup\n",
      "\n",
      "High-level view\n",
      "\n",
      "Configure bash for your laptop\n",
      "\n",
      "Linux and MacOS\n",
      "\n",
      "Windows\n",
      "\n",
      "Configure .ssh for your laptop\n",
      "\n",
      "Configure .ssh for the server\n",
      "\n",
      "Configure bash for the server (advanced)\n",
      "\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# Define a user query.\n",
    "query = \"What are the guidelines for setting up a new project?\"\n",
    "\n",
    "# Query the chatbot.\n",
    "response = qa_chain({\"query\": query})\n",
    "\n",
    "# Display the answer and source documents.\n",
    "print(f\"Answer:\\n{response['result']}\\n\")\n",
    "print(\"Source Documents:\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(f\"- Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Excerpt: {doc.page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d2ca4",
   "metadata": {},
   "source": [
    "## Step 6: Dynamic Updates\n",
    "\n",
    "What if the documentation changes? We'll handle this by monitoring the folder for new or modified files.\n",
    "The vector store will be updated dynamically to ensure the chatbot stays up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb2c959f-0def-4a38-b329-34bf7f3206bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  Found 16 markdown files in docs\n"
     ]
    }
   ],
   "source": [
    "ut.update_vector_store_from_changes(\n",
    "    config,\n",
    "    vector_store,\n",
    "    embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260331ce",
   "metadata": {},
   "source": [
    "## Step 7: Enhancements - Personalization\n",
    "\n",
    "We can extend the chatbot to include personalized responses:\n",
    "- Filter documents by metadata (e.g., tags, categories).\n",
    "- Customize responses based on user preferences.\n",
    "\n",
    "For example, users can ask for specific sections of the documentation or request summaries tailored to their needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e2de353-2f56-41e4-bf35-4d6c036bd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO  HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Answer:\n",
      "I don't know.\n",
      "\n",
      "Source Documents:\n",
      "- Source: docs/onboarding/all.onboarding_checklist.reference.md\n",
      "  Excerpt: Onboarding Checklist\n",
      "\n",
      "Onboarding process for a new team member\n",
      "\n",
      "Meta\n",
      "\n",
      "Make on-boarding automatic\n",
      "\n",
      "Be patient\n",
      "\n",
      "Ask for confirmation\n",
      "\n",
      "Make on-boarding similar to our work routine\n",
      "\n",
      "Improve on-boarding pr\n",
      "- Source: docs/onboarding/all.onboarding_checklist.reference.md\n",
      "  Excerpt: Ask for confirmation of all the actions, e.g.,\n",
      "\n",
      "\"Does this and that work?\"\n",
      "\n",
      "\"Did you receive the email?\"\n",
      "\n",
      "\"Can you log in?\"\n",
      "\n",
      "Make the new team member follow the instructions so that they can get famil\n",
      "- Source: docs/onboarding/ck.hiring_process.how_to_guide.md\n",
      "  Excerpt: Follow the instructions in all.onboarding_checklist.reference.md\n",
      "\n",
      "HiringMeister: once the full onboarding is complete, organize more complex tasks to test their development and problem-solving skills\n",
      "\n",
      "- Source: docs/onboarding/all.onboarding_checklist.reference.md\n",
      "  Excerpt: We use it only to track the time automatically and as HR\n",
      "\n",
      "[ ] Team member:\n",
      "\n",
      "Confirm access to Hubstaff\n",
      "\n",
      "Read Instructions for Hubstaff\n",
      "\n",
      "IT setup\n",
      "\n",
      "[ ] Team leader: File an issue with this checklist\n",
      "\n",
      "Th\n"
     ]
    }
   ],
   "source": [
    "# Example query with personalized intent.\n",
    "personalized_query = \"Show me onboarding guidelines for new employees.\"\n",
    "\n",
    "# Query the chatbot.\n",
    "personalized_response = qa_chain({\"query\": personalized_query})\n",
    "\n",
    "# Display the personalized response.\n",
    "print(f\"Answer:\\n{personalized_response['result']}\\n\")\n",
    "print(\"Source Documents:\")\n",
    "for doc in personalized_response[\"source_documents\"]:\n",
    "    print(f\"- Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Excerpt: {doc.page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e7b90",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this script, we:\n",
    "1. Parsed and processed Markdown documentation.\n",
    "2. Embedded document chunks into a FAISS vector store for efficient retrieval.\n",
    "3. Built a RetrievalQA chain for context-aware question answering.\n",
    "4. Enabled dynamic updates to handle changing documentation.\n",
    "5. Enhanced the chatbot with personalized query handling.\n",
    "\n",
    "This showcases how LangChain can be used to build intelligent, flexible chatbots tailored for specific tasks."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
