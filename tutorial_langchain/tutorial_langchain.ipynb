{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f91f41-afe7-49fa-9859-397009613558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab54142-1414-4d82-a6e1-1a51db624dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427c7461-6d5c-4125-a2f4-2a57e5b62b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to parse and structure Markdown files\n",
    "def parse_markdown_files(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        # Create a Document object for each file\n",
    "        documents.append(Document(page_content=content, metadata={\"source\": file_path.name}))\n",
    "    return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2de353-2f56-41e4-bf35-4d6c036bd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter\n",
    "# TODO(Sonaal): Add details on how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9f8f9a-97f4-43c5-8aed-df5b581ac060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: all.how_write_tutorials.how_to_guide.md\n",
      "Content: <!-- toc -->\n",
      "\n",
      "- [Tutorials \"Learn X in 60 minutes\"](#tutorials-learn-x-in-60-minutes)\n",
      "  * [What are the goals for each tutorial](#what-are-the-goals-for-each-tutorial)\n",
      "\n",
      "<!-- tocstop -->\n",
      "\n",
      "# Tutorials \"Learn X in 60 minutes\"\n",
      "\n",
      "The goal is to give everything needed for one person to become familiar with a\n",
      "Big data / AI / LLM / data science technology in 60 minutes.\n",
      "\n",
      "- Each tutorial conceptually corresponds to a blog entry.\n",
      "\n",
      "Source: all.how_write_tutorials.how_to_guide.md\n",
      "Content: Each tutorial corresponds to a directory in the `//tutorials` repo\n",
      "[https://github.com/causify-ai/tutorials](https://github.com/causify-ai/tutorials)\n",
      "with\n",
      "\n",
      "Source: all.how_write_tutorials.how_to_guide.md\n",
      "Content: - A markdown \\`XYZ.API.md\\` about the API and the software layer written by us\n",
      "  on top of the native API\n",
      "- A markdown `XYZ.example.md` with a full example of an application using the\n",
      "  API\n",
      "- A Docker container with everything you need in our Causify dev-system format\n",
      "- A Jupyter notebook with an example of APIs\n",
      "- A Jupyter notebook with a full example\n",
      "\n",
      "## What are the goals for each tutorial\n",
      "\n",
      "Docker container\n",
      "\n",
      "Source: all.how_write_tutorials.how_to_guide.md\n",
      "Content: Docker container\n",
      "\n",
      "- Provides a Docker container with everything installed and ready to run\n",
      "  tutorials and develop with that technology\n",
      "  - Often installing the package and get it to work takes long to figure out\n",
      "- All the code is on GitHub in a common format to all tutorials\n",
      "\n",
      "Jupyter notebooks\n",
      "\n",
      "Source: all.how_write_tutorials.how_to_guide.md\n",
      "Content: - Each Jupyter notebook should\n",
      "  - Be unit tested so that you are guaranteed that it works\n",
      "    - It's super frustrating when a tutorial doesn't work because the version of\n",
      "      the library is not compatible with the code anymore\n",
      "  - Be self-contained and linear: each example is explained thoroughly without\n",
      "    having to jump from tutorial to tutorial\n",
      "    - Each cell and its output is commented and explained\n",
      "  - Run end-to-end after a restart (we can add a unit test for it)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: List all markdown files in a directory\n",
    "def list_markdown_files(directory):\n",
    "    return list(Path(directory).rglob(\"*.md\"))\n",
    "\n",
    "# Directory containing Markdown files\n",
    "directory = \"../docs\"\n",
    "\n",
    "# List Markdown files\n",
    "markdown_files = list_markdown_files(directory)\n",
    "\n",
    "# Parse Markdown files into LangChain documents\n",
    "documents = parse_markdown_files(markdown_files)\n",
    "\n",
    "# Split long documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print sample chunked documents\n",
    "for doc in split_documents[:5]:\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda235ca-36f4-4b2e-a0f8-3f51d4bf08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and Store Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be86c16-f178-42cf-b0c0-911c84c0d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_302/34750187.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embed and store split_documents\n",
    "vector_store = FAISS.from_documents(split_documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d6b0da-f9cb-4790-ba72-b22158f1510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a4a0dc-967f-4225-ba19-54f444498bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Create the QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8920b1c6-1f29-4092-a4ce-672fdc339033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The guidelines for creating a new project, as per the context, include:\n",
      "\n",
      "1. The project should be documented using Markdown documents. These documents should cover:\n",
      "   - A description of the package.\n",
      "   - The problem it solves.\n",
      "   - Alternatives to the package, both open source and commercial, with comments about their advantages and disadvantages.\n",
      "   - A description of the native API.\n",
      "   - A description of the Docker container.\n",
      "   - Visual aids with mermaid to enhance understanding, such as flow diagrams, data transformation steps, and plots.\n",
      "   - References to books and in-depth tutorials that have been run and are considered to be excellent.\n",
      "   - All sources should be referred and acknowledged.\n",
      "\n",
      "2. The project should include Jupyter notebooks that:\n",
      "   - Are unit tested to ensure they work.\n",
      "   - Are self-contained and linear, with each example explained thoroughly without having to jump from tutorial to tutorial.\n",
      "   - Each cell and its output is commented and explained.\n",
      "   - Can run end-to-end after a restart.\n",
      "\n",
      "3. The project should cover the following topics: Git, Docker, Docker compose, Postgres, MongoDB, Airflow, Dask, GitHub, and Spark. This is the same approach used in DATA605 tutorials.\n",
      "\n",
      "Source Documents:\n",
      "File: all.how_write_tutorials.how_to_guide.md\n",
      "Excerpt: Markdown documents should cover:...\n",
      "File: all.how_write_tutorials.how_to_guide.md\n",
      "Excerpt: This is the same approach we use in DATA605 tutorials\n",
      "https://github.com/gpsaggese/umd\\_data605/tree/main/tutorials, e.g.,\n",
      "\n",
      "- Git\n",
      "- Docker\n",
      "- Docker compose\n",
      "- Postgres\n",
      "- MongoDB\n",
      "- Airflow\n",
      "- Dask\n",
      "- GitH...\n",
      "File: all.how_write_tutorials.how_to_guide.md\n",
      "Excerpt: - What it is the package\n",
      "- What problem it solves\n",
      "- What are the alternatives, both open source and commercial with comments about\n",
      "  advantages and disadvantages\n",
      "- Describe the native API\n",
      "- Descriptio...\n",
      "File: all.how_write_tutorials.how_to_guide.md\n",
      "Excerpt: - Each Jupyter notebook should\n",
      "  - Be unit tested so that you are guaranteed that it works\n",
      "    - It's super frustrating when a tutorial doesn't work because the version of\n",
      "      the library is not com...\n"
     ]
    }
   ],
   "source": [
    "# User's question\n",
    "query = \"What are the guidelines on creating new project\"\n",
    "\n",
    "# Get the answer and source documents\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "# Print the answer\n",
    "print(\"Answer:\")\n",
    "print(result['result'])\n",
    "\n",
    "# Print the source file references\n",
    "print(\"\\nSource Documents:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"File: {doc.metadata['source']}\")\n",
    "    print(f\"Excerpt: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aef9b8-88cd-4088-87f5-c88faa6eb914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
